docker pull redis:7.2.3
docker images
docker run --name redis -d -p 6379:6379 -v C:/DevApp/redis/data:/data --restart=always --privileged=true redis:7.2.3
docker PS
docker logs redis

docker exec -it redis redis-cli -- 进入redis

docker run --name redis -e REDIS_PASSWORD=123456 -d -p 6379:6379 -v C:/DevApp/redis/data:/data --restart=always --privileged=true redis:7.2.3


----------------------------------------------------------------------------持久化：----------------------------------------------------------------------------
    1. RDB（Redis DB）  某一个时间节点上的完整副本   dump.rdb          /save<secondes><changes>         
        Redis 是单线程的， during RDB, redis都是阻塞的
        save 3600 1   -- means in 3600 secondes, if modifed 1 time, then will perform
        bgsave -- 单独子线程，用来备份文件， 所以不阻塞主线程 -- 但是这个时间内Redis 还是不能处理请求

        Advantage:
            1. 适合按照业务定时备份
            2. 适合大规模的数据恢复
            3. 在内存中加载数据， 比AOF快
        Disadvantage：
            1. 丢失数据 -- 某个时间节点的副本
            2. fork() bgsave 子线程，如果数据大，占用内存，慢

        触发机制： --何时产生rdb 文件
            1. 配置文件中的配置
            2. 手动save/pgsave
            3. 执行flushall/flushdb， 产生空的rdb文件
            4. 执行shutdown，且未设置开始AOF
            5. 主从复制时，从节点自动触发

        禁止使用： 命令： save "" 


    2. AOF (Append Only File)(优先)         appendonly.aof                       appendonly yes
        将数据不仅放在内存中，还会放在一个AOF 文件中，用日志的形式记录所有操作
        so when redis 重启，会读取AOF文件，重构整个数据内容

        同步策略：

        重写机制： -- 同步文件越来越大，    ex: 1: set key v1,  then set key v2, the set key v3  -- file will save them all
                    占用内存越来越大
                    恢复时间也会越来越长
            so： 文件大于设定峰值，会自动启用AOF文件内容压缩， 只保留恢复数据的最小指令集（只保留Key最后一次修改值 -- oly save key v3 in file）
            自动触发：配置
            手动触发：手动触发bgrewriteaof 命令

            重写原理：去内存读取所有现存的键值对，生成一个新的文件，替换原有文件


        Advantage:
            保护数据不丢失，性能好，可做紧急修复
        Disadvantage：
            1. AOF 文件 比 RDB 文件大
            2. AOF运行效率低于RDB


----------------------------------------------------------------------------事务----------------------------------------------------------------------------
DB:                                 Redis

begin                               multi

sql1                                cmd1
sql2                                cmd2

commit                              exec

    1. 单线程执行命令队列        -- 同一时间只有这一个客户端的命令被执行
    2. 不保证都能成功            -- 不能全成功or 全失败

命令：   multi :  开启事务
        discard： 取消所有
        exec：    执行所有
        watch:    监听具体key，exec前会查一次，当前值是否被改变， 若改了，则所有事务都不会被执行
        unwatch   放弃监听， 用在watch后

----------------------------------------------------------------------------管道 pipeline----------------------------------------------------------------------------
优化频繁命令往返造成的性能瓶颈    -- queue  先进先出 保证顺序          mset -- redis 原生批处理，原子性，一次一种命令

1. add the command in a file txt
2. cat cmd.txt | redis-cli -a username --pipe
3. 命令数量需要合理，不然也会占用内存

----------------------------------------------------------------------------pub/sub----------------------------------------------------------------------------

----------------------------------------------------------------------------主从复制 Replica----------------------------------------------------------------------------
    读写分离：
        主节点写， 副节点读   
    一主多从：
        配从不配主
        salve readOnly
        master - requirepass
        salve - masterauth

    基本操作：
        info replication                -- 查看主从节点
        replicaof masterIP masterPort   -- set int slave server, normally set in redis.conf file
        slaveof masterIP masterPort     -- slave 切换 master
        slaveof no one                  -- 成为master


    1. 读写分离：
        主节点写， 副节点读 
        主节点通过异步线程把数据发送给所有从节点，从节点再更新数据  
            a. slave created, will send sync request to master
            b. master get the sync request, will genereate a RDB file, then send RDS file & cache to salve
            c. salve get the response, then load all data in RAM
            d. master send heardbeat to slave 10s
            e. 增量复制: master send newly added data to salve
            f. 从机down，then restart： 
                master，salve will save a offset,masterId in backlog, 
                once slave re-up, Master will only send the data a

        slave will save all data of master, even down for a while
    2. master write&read, slave readOnly
    3. master down, slave will always be salve, wait for master
    4. after master restart, all still same (data, relationship)
    5. salve server can be the master server of other salves
    
    Disadvantage：
        1. Data from Master to salve, 有延时
        2. Master down
            默认salve只会等待

            !!!!!!  -- So need sentinel to set the Master once Master down

----------------------------------------------------------------------------哨兵模式(sentinel----------------------------------------------------------------------------
自动的故障转移， 一般也会有奇数个(3)哨兵来保障高可用   Sentinel is used when not using Redis Cluster !!!!!!

    1. 主从监控

    2. 消息通知             发送故障转移结果给客户端 

    3. 自动故障转移         主从切换 根据投票数选出master
        SDown主观下线        -- 单个Sentinel发现master down（发送PING心跳，单位时间Master内无回复--时间set inconfig）
        ODown客观下线        -- 多个sentinel发现master down
        Raft算法（先到先得） 选举Sentinel Leader  -- 由sentinel leader去推动选举切换master

            -->> Master 选举算法  --  都是由sentinel 完成
                a. 某个slave选举成为Master
                    priority            --高    （set in redis.conf, 数字越小优先级越高）
                    replication Offset  --大    （谁的数据多）
                    run id              --小    （Redis 服务器的随机标识符）
                b. 成为master -- 选中的salve执行 ， 再salveof masterId masterPort 让别的节点成为其从节点
                    sentinel leader 对新master执行 slaveof no one 成为master
                    sentinel leader 对其余slave执行 slaveof no one 成为新master的salve
                c. 如果老Master back， 会成为新Master的slave
                    sentinel leader 降级老master，成为新的slave

    4. 配置中心             客户端连接哨兵获得切换后的Redis主节点地址

    哨兵节点数据多个，集群，高可用
    哨兵节点数量奇数
    哨兵节点配置一致
    哨兵+主从复制，不能保证数据零丢失
        从Master down，到新的Master选举，需要时间，对于生产有延时
----------------------------------------------------------------------------Redis Cluster----------------------------------------------------------------------------
CLUSTER NODES   登录需要最后加上  -c
CLUSTER KEYSLOT 查看槽位

    1. 槽位slot     cluster's key space is split into 16384个槽 (redis doc suggests max size less than 1000)
        hash slot 哈希槽
        key 使用CRC16算法取模，来决定放在那个节点  --  hash_slot= CRC16(key)mod 16384

    2. 分片
        cluster 中每一个Redis示例都是整体数据的一个分片

    主从自动分配，自动避免主从再同一个服务器上


    
<<<<哈希取余分区
        hash(key)/master 节点个数 -- 万一节点个数变化（增/删），数据变化较大

<<<<一致性哈希算法
        hash(key)%2^23-1            hash key对 2^23取模，无论节点怎么变，取模结果不变
        哈希环，设置 0 = 2^23，从0 到2^23形成一个圆环
        落键规则：
            1. hash(node)%2^23-1
            2. hash(key)%2^23-1
            3. key 取模后，顺时针行走(从小到大)，则将数据放在遇到的第一个节点上

        优点：
            1. 容错
                因为落键规则，一个节点挂了，自动继续顺时针放到下一个遇到的节点
            2. 扩展
                因为落键规则，扩展好，新增节点影响数据少
        缺点：
            数据倾斜    -- 因为落键规则，节点少的时候，容易数据分布到节点不均匀

<<<<哈希槽分区    2^14=16384
    数组： [0，2^14-1]   就是哈希槽

    数据  -->  哈希槽  -->  redis

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    为什么哈希槽大小 16384     CRC16算法产生的hash值有16bit，该算法可以产生2^16=65536个值

    1. 如果槽位 65536， 发送心跳包过大，浪费带宽    --心跳包包含该节点的所有哈希槽的配置
        65536/8/1024=8kb
        16384/8/1024=2kb
    2. redis 集群主节点数小于1000
        节点越多，心跳包携带数据越多，可能网络堵塞，所以1000 以内的，16384槽位足够
    3. 槽位越小，节点越少，压缩比高，容易传输
        压缩比：Redis主节点配置信息中的哈希槽 通过bitmap保存，传输中对bitmap进行压缩，
            节点越多，压缩率低
            节点越少，哈希槽越多，压缩率低


------------------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> 高级
单线程问题： 大数据key删除卡顿
从4开始引入 unlink key/flushall async
Redis6&7, 多线程默认关闭, need to open manually in redis.conf
IO 读写变成多线程，命令执行依旧是主线程 -- 所以不会出现线程安全问题

-------------------BIG KEY >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

生产一般禁用 KEYS * / flushall/ fluahdb   can ban those commands in redis.conf file 
better: scan 0 match k* count 10

>>>BigKey危害：
    超时删除，大key做阻
    内存不均，集群迁移困难

>>>什么是BigKey：
    String 10KB 以内, hash,list, set, zset 元素 5000 以内

>>>怎么产生BigKey：
    一直变大的报表...

>>>怎么查看BigKey：
    redis-cli --bigkeys
    MEMORY USAGE k1


>>>删除BigKey：
    String -- del  过大 unlink
    hash    -- hscan 获取key-val, 再 hdel 删除field， 最后最后再del
    list    -- ltrim 渐进式删除
    set     -- sscan 部分获取， srem 删除元素
    zset    -- zscan 部分获取， ZREMRANGEBYRANK 删除

>>>bigkey调优
    惰性释放 lazyfree       in redis.conf  LAZY FREEING
        lazyfree-lazy-server-del yes
        lazyfree-lazy-user-del yes
        replica-lazy-flush yes
        修改上述， del flush 会成为 unlink 类似的异步操作，不会阻塞主线程
    
-------------------缓存双写一致 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
        数据一致性 -- DB  cache 一致

>>>>>>>>双检加锁策略    
        大量数据访问,cache中不存在，DB中也不存在    --   此时会用同一个查询大量访问数据库
        1. 查询方法加上一个互斥锁   --  防止大量访问数据库
            a. 第一个线程查cache，有直接返回
            b. cache不存在，加互斥锁，再查一遍cache
            c. cache确实没有，再去数据库
            d. 拿到数据库数据，写到cache，再返回
            
>>>>>>>>数据库缓存一致   --  设置cache 过期时间，定期清理并回写

        >>延时双删  --先删除cache，再更新DB
            a. 删除cache
            b. 更新数据库
            c. DB更新成功之后, 再删一次cache    -- 需要确保两次删除时间，大于单次查询DB并添加cache的时间！！

>>>>>>>>canel  可以监听MySql数据变动，并通知Redis
        模仿MySql主从复制，伪装为slave，发送dump 协议到master，master收到dump请求，开始推送binary log 给canel，canel再发给第三方，通知数据改动

>>>>>>>>mysql+canel+redis 双写一致

>>>>>>>>hyperloglog
        用来做基数统计的一种算法 -- 去重            只会根据输入元素来计算！基数！， 不会储存元素本身， 无法返回输入的元素  
        ！！--  缺点：牺牲准确度换取空间，有误差 0.81%

        每个HyperLogLog键只需要12KB内存，就可以计算2^64个不同的 ！基 数！

        PFADD
        PFCOUNT
        PFMERGE

        作用：统计UV-USER VISIT
            PV-PAGE VIEW
            UAV-USER ACTIVE VIEW

>>>>>>>>GEO

        GEOADD      添加   
        GEOPOS      查询
        GEOHASH     geohash算法生成的base32编码值
        GEODIST     两点距离
        GEORADIUS   以半径为中心，查询附近
        GEORADIUSBYMEMBER   查两点附近

>>>>>>>>BitMap
        0 1 组成的二进制数组   适合状态统计

>>>>>>>>布隆过滤器 BloomFilter      本质是一种数据结构

    由  一个初始值为0的bitmap       --取bitmap数组长度
    和  多个哈希函数构成            --多个hash函数运算  key 得到多个整数结果， 再分别对bitmap数组长度取模，得到多个数组下标！！！  --数组下标保存在bitmap

    用来快速判断集合中是否存在某个元素   的数据结构

    添加key！！！
        
        >>>>>>
            对key hash运算得到整数索引，                --有多个hash函数
            对  bitmap 数组长度    取模运算得到位置, 得到位置，
            将对应位置设为1

    查询key！！！
        
        >>>>>>
            只要有一位是0，就不存在


    ex:  三个函数   hash(key) mod  --     得到三个坑位：   坑位17=1，22=1，35=1
        判断key是否存在 --  对应三个坑位必须都是1，有0则肯定不存在

    高效插入查询，占用空间小， 返回结果  不确定性 + 不完美

    一个元素判定结果：      
        存在    --  元素不一定存在  -- 可能被其他顶用坑位（hash冲突）
        不存在  --  元素一定不存在

    可以添加元素，不能删除元素  --  hash冲突，不确定删除坑位到底是删除的是谁，一个坑位可能存在多个元素

    综上：  
        如果BloomFilter 判断元素不在一个集合中，那一定不存在 
        实际元素数量不能远大于初始数量，一次给够，避免扩容
        实际元素量>初始化量 --  重建布隆过滤器


    >>>应用：
        先布隆过滤器判断是否存在，不存在直接返回，存在则查询cache，数据库，   --  不查询数据库

    Advantage:  
        高效插入 查询
        内存占bit空间少
    Disadvantage：
        不能删除
        存在误判


----------缓存预热--------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    1. 不DB 修改后不主动刷新，等待第一次查询再自动加载
    2. 程序上线后 测试 主动提前触发
    3. 运行脚本，程序 主动加载

----------缓存雪崩--------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    1. 设置key过期时间错开or不过期
    2. 使用集群 高可用
    3. 多缓存结合 --  ehcache + redis
    4. 服务降级 展示错误页面，同时后端修复


----------缓存击穿--------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    大量请求同时查询同一个Key，key正好失效的，导致大量请求到数据库

    热点Key失效，暴打DB

    1. 设置差异失效时间，热点key 不设置失效时间
        用两套缓存，差异失效，保证始终有一个缓存可以使用
            >>>>>>>>查询：
                查A缓存
                    无  --  查B 缓存
                                无  --  查DB
                                有  --  return
                    有  -- return
            
            >>>>>>>>更新：
                更新B缓存， 先expire，再add，设置过期时间大于A缓存过期时间
                再更新A缓存

            主A，从B， 每次先更新B，设置B 过期时间大于A
                        再更新A缓存

    2. 双检加锁
        >>>>>>>>双检加锁策略    
        1. 查询方法加上一个互斥锁   --  防止大量访问数据库
            a. 第一个线程查cache，有直接返回
            b. cache不存在，加互斥锁，再查一遍cache
            c. cache确实没有，再去数据库
            d. 拿到数据库数据，写到cache，再返回

----------缓存穿透--------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> 
    cache中不存在，DB中也不存在，造成大量访问数据库
    
    --->>> 使用布隆过滤器
        1. 已有数据放过滤器中
        2. 所有请求先走过滤器
            无  --  直接返回无
            有  --  再去redis Cache
                    cache 大概率有  --  返回结果
                    cache 无    --  再去数据库

    空对象缓存      --          治标不治本
        约定默认空值， 比如 字符串： Nah, 并存入redis  --  设置过期时间 短