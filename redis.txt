docker pull redis:7.2.3
docker images
docker run --name redis -d -p 6379:6379 -v C:/DevApp/redis/data:/data --restart=always --privileged=true redis:7.2.3
docker PS
docker logs redis

docker exec -it redis redis-cli -- 进入redis

docker run --name redis -e REDIS_PASSWORD=123456 -d -p 6379:6379 -v C:/DevApp/redis/data:/data --restart=always --privileged=true redis:7.2.3


----------------------------------------------------------------------------持久化：----------------------------------------------------------------------------
    1. RDB（Redis DB）  某一个时间节点上的完整副本   dump.rdb          /save<secondes><changes>         
        Redis 是单线程的， during RDB, redis都是阻塞的
        save 3600 1   -- means in 3600 secondes, if modifed 1 time, then will perform
        bgsave -- 单独子线程，用来备份文件， 所以不阻塞主线程 -- 但是这个时间内Redis 还是不能处理请求

        Advantage:
            1. 适合按照业务定时备份
            2. 适合大规模的数据恢复
            3. 在内存中加载数据， 比AOF快
        Disadvantage：
            1. 丢失数据 -- 某个时间节点的副本
            2. fork() bgsave 子线程，如果数据大，占用内存，慢

        触发机制： --何时产生rdb 文件
            1. 配置文件中的配置
            2. 手动save/pgsave
            3. 执行flushall/flushdb， 产生空的rdb文件
            4. 执行shutdown，且未设置开始AOF
            5. 主从复制时，从节点自动触发

        禁止使用： 命令： save "" 


    2. AOF (Append Only File)(优先)         appendonly.aof                       appendonly yes
        将数据不仅放在内存中，还会放在一个AOF 文件中，用日志的形式记录所有操作
        so when redis 重启，会读取AOF文件，重构整个数据内容

        同步策略：

        重写机制： -- 同步文件越来越大，    ex: 1: set key v1,  then set key v2, the set key v3  -- file will save them all
                    占用内存越来越大
                    恢复时间也会越来越长
            so： 文件大于设定峰值，会自动启用AOF文件内容压缩， 只保留恢复数据的最小指令集（只保留Key最后一次修改值 -- oly save key v3 in file）
            自动触发：配置
            手动触发：手动触发bgrewriteaof 命令

            重写原理：去内存读取所有现存的键值对，生成一个新的文件，替换原有文件


        Advantage:
            保护数据不丢失，性能好，可做紧急修复
        Disadvantage：
            1. AOF 文件 比 RDB 文件大
            2. AOF运行效率低于RDB


----------------------------------------------------------------------------事务----------------------------------------------------------------------------
DB:                                 Redis

begin                               multi

sql1                                cmd1
sql2                                cmd2

commit                              exec

    1. 单线程执行命令队列        -- 同一时间只有这一个客户端的命令被执行
    2. 不保证都能成功            -- 不能全成功or 全失败

命令：   multi :  开启事务
        discard： 取消所有
        exec：    执行所有
        watch:    监听具体key，exec前会查一次，当前值是否被改变， 若改了，则所有事务都不会被执行
        unwatch   放弃监听， 用在watch后

----------------------------------------------------------------------------管道 pipeline----------------------------------------------------------------------------
优化频繁命令往返造成的性能瓶颈    -- queue  先进先出 保证顺序          mset -- redis 原生批处理，原子性，一次一种命令

1. add the command in a file txt
2. cat cmd.txt | redis-cli -a username --pipe
3. 命令数量需要合理，不然也会占用内存

----------------------------------------------------------------------------pub/sub----------------------------------------------------------------------------

----------------------------------------------------------------------------主从复制 Replica----------------------------------------------------------------------------
    读写分离：
        主节点写， 副节点读   
    一主多从：
        配从不配主
        salve readOnly
        master - requirepass
        salve - masterauth

    基本操作：
        info replication                -- 查看主从节点
        replicaof masterIP masterPort   -- set int slave server, normally set in redis.conf file
        slaveof masterIP masterPort     -- slave 切换 master
        slaveof no one                  -- 成为master


    1. 读写分离：
        主节点写， 副节点读 
        主节点通过异步线程把数据发送给所有从节点，从节点再更新数据  
            a. slave created, will send sync request to master
            b. master get the sync request, will genereate a RDB file, then send RDS file & cache to salve
            c. salve get the response, then load all data in RAM
            d. master send heardbeat to slave 10s
            e. 增量复制: master send newly added data to salve
            f. 从机down，then restart： 
                master，salve will save a offset,masterId in backlog, 
                once slave re-up, Master will only send the data a

        slave will save all data of master, even down for a while
    2. master write&read, slave readOnly
    3. master down, slave will always be salve, wait for master
    4. after master restart, all still same (data, relationship)
    5. salve server can be the master server of other salves
    
    Disadvantage：
        1. Data from Master to salve, 有延时
        2. Master down
            默认salve只会等待

            !!!!!!  -- So need sentinel to set the Master once Master down

----------------------------------------------------------------------------哨兵模式(sentinel----------------------------------------------------------------------------
自动的故障转移， 一般也会有奇数个(3)哨兵来保障高可用   Sentinel is used when not using Redis Cluster !!!!!!

    1. 主从监控

    2. 消息通知             发送故障转移结果给客户端 

    3. 自动故障转移         主从切换 根据投票数选出master
        SDown主观下线        -- 单个Sentinel发现master down（发送PING心跳，单位时间Master内无回复--时间set inconfig）
        ODown客观下线        -- 多个sentinel发现master down
        Raft算法（先到先得） 选举Sentinel Leader  -- 由sentinel leader去推动选举切换master

            -->> Master 选举算法  --  都是由sentinel 完成
                a. 某个slave选举成为Master
                    priority            --高    （set in redis.conf, 数字越小优先级越高）
                    replication Offset  --大    （谁的数据多）
                    run id              --小    （Redis 服务器的随机标识符）
                b. 成为master -- 选中的salve执行 ， 再salveof masterId masterPort 让别的节点成为其从节点
                    sentinel leader 对新master执行 slaveof no one 成为master
                    sentinel leader 对其余slave执行 slaveof no one 成为新master的salve
                c. 如果老Master back， 会成为新Master的slave
                    sentinel leader 降级老master，成为新的slave

    4. 配置中心             客户端连接哨兵获得切换后的Redis主节点地址

    哨兵节点数据多个，集群，高可用
    哨兵节点数量奇数
    哨兵节点配置一致
    哨兵+主从复制，不能保证数据零丢失
        从Master down，到新的Master选举，需要时间，对于生产有延时
----------------------------------------------------------------------------Redis Cluster----------------------------------------------------------------------------
CLUSTER NODES   登录需要最后加上  -c
CLUSTER KEYSLOT 查看槽位

    1. 槽位slot     cluster's key space is split into 16384个槽 (redis doc suggests max size less than 1000)
        hash slot 哈希槽
        key 使用CRC16算法取模，来决定放在那个节点  --  hash_slot= CRC16(key)mod 16384

    2. 分片
        cluster 中每一个Redis示例都是整体数据的一个分片

    主从自动分配，自动避免主从再同一个服务器上


    
<<<<哈希取余分区
        hash(key)/master 节点个数 -- 万一节点个数变化（增/删），数据变化较大

<<<<一致性哈希算法
        hash(key)%2^23-1            hash key对 2^23取模，无论节点怎么变，取模结果不变
        哈希环，设置 0 = 2^23，从0 到2^23形成一个圆环
        落键规则：
            1. hash(node)%2^23-1
            2. hash(key)%2^23-1
            3. key 取模后，顺时针行走(从小到大)，则将数据放在遇到的第一个节点上

        优点：
            1. 容错
                因为落键规则，一个节点挂了，自动继续顺时针放到下一个遇到的节点
            2. 扩展
                因为落键规则，扩展好，新增节点影响数据少
        缺点：
            数据倾斜    -- 因为落键规则，节点少的时候，容易数据分布到节点不均匀

<<<<哈希槽分区    2^14=16384
    数组： [0，2^14-1]   就是哈希槽

    数据  -->  哈希槽  -->  redis

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    为什么哈希槽大小 16384     CRC16算法产生的hash值有16bit，该算法可以产生2^16=65536个值

    1. 如果槽位 65536， 发送心跳包过大，浪费带宽    --心跳包包含该节点的所有哈希槽的配置
        65536/8/1024=8kb
        16384/8/1024=2kb
    2. redis 集群主节点数小于1000
        节点越多，心跳包携带数据越多，可能网络堵塞，所以1000 以内的，16384槽位足够
    3. 槽位越小，节点越少，压缩比高，容易传输
        压缩比：Redis主节点配置信息中的哈希槽 通过bitmap保存，传输中对bitmap进行压缩，
            节点越多，压缩率低
            节点越少，哈希槽越多，压缩率低
