------------------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> 高级
单线程问题： 大数据key删除卡顿
从4开始引入 unlink key/flushall async
Redis6&7, 多线程默认关闭, need to open manually in redis.conf
IO 读写变成多线程，命令执行依旧是主线程 -- 所以不会出现线程安全问题

-------------------BIG KEY >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>--------------------------------------

生产一般禁用 KEYS * / flushall/ fluahdb   can ban those commands in redis.conf file 
better: scan 0 match k* count 10

>>>BigKey危害：
    超时删除，大key做阻
    内存不均，集群迁移困难

>>>什么是BigKey：
    String 10KB 以内, hash,list, set, zset 元素 5000 以内

>>>怎么产生BigKey：
    一直变大的报表...

>>>怎么查看BigKey：
    redis-cli --bigkeys
    MEMORY USAGE k1


>>>删除BigKey：
    String -- del  过大 unlink
    hash    -- hscan 获取key-val, 再 hdel 删除field， 最后最后再del
    list    -- ltrim 渐进式删除
    set     -- sscan 部分获取， srem 删除元素
    zset    -- zscan 部分获取， ZREMRANGEBYRANK 删除

>>>bigkey调优
    惰性释放 lazyfree       in redis.conf  LAZY FREEING
        lazyfree-lazy-server-del yes
        lazyfree-lazy-user-del yes
        replica-lazy-flush yes
        修改上述， del flush 会成为 unlink 类似的异步操作，不会阻塞主线程
    
-------------------缓存双写一致 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
        数据一致性 -- DB  cache 一致

    >>>>>>>>双检加锁策略    
        大量数据访问,cache中不存在，DB中也不存在    --   此时会用同一个查询大量访问数据库
        1. 查询方法加上一个互斥锁   --  防止大量访问数据库
            a. 第一个线程查cache，有直接返回
            b. cache不存在，加互斥锁，再查一遍cache
            c. cache确实没有，再去数据库
            d. 拿到数据库数据，写到cache，再返回
            
    >>>>>>>>数据库缓存一致   --  设置cache 过期时间，定期清理并回写

        >>延时双删  --先删除cache，再更新DB
            a. 删除cache
            b. 更新数据库
            c. DB更新成功之后, 再删一次cache    -- 需要确保两次删除时间，大于单次查询DB并添加cache的时间！！

    >>>>>>>>canel  可以监听MySql数据变动，并通知Redis
        模仿MySql主从复制，伪装为slave，发送dump 协议到master，master收到dump请求，开始推送binary log 给canel，canel再发给第三方，通知数据改动

    >>>>>>>>mysql+canel+redis 双写一致
    
-----------------------------------------------------------------------------------------------
    >>>>>>>>hyperloglog
        用来做基数统计的一种算法 -- 去重            只会根据输入元素来计算！基数！， 不会储存元素本身， 无法返回输入的元素  
        ！！--  缺点：牺牲准确度换取空间，有误差 0.81%

        每个HyperLogLog键只需要12KB内存，就可以计算2^64个不同的 ！基 数！

        PFADD
        PFCOUNT
        PFMERGE

        作用：统计UV-USER VISIT
            PV-PAGE VIEW
            UAV-USER ACTIVE VIEW
-----------------------------------------------------------------------------------------------
    >>>>>>>>GEO

        GEOADD      添加   
        GEOPOS      查询
        GEOHASH     geohash算法生成的base32编码值
        GEODIST     两点距离
        GEORADIUS   以半径为中心，查询附近
        GEORADIUSBYMEMBER   查两点附近
        
-----------------------------------------------------------------------------------------------
    >>>>>>>>BitMap
        0 1 组成的二进制数组   适合状态统计

-----------------------------------------------------------------------------------------------
    >>>>>>>>布隆过滤器 BloomFilter      本质是一种数据结构

    由  一个初始值为0的bitmap       --取bitmap数组长度
    和  多个哈希函数构成            --多个hash函数运算  key 得到多个整数结果， 再分别对bitmap数组长度取模，得到多个数组下标！！！  --数组下标保存在bitmap

    用来快速判断集合中是否存在某个元素   的数据结构

    添加key！！！
        
        >>>>>>
            对key hash运算得到整数索引，                --有多个hash函数
            对  bitmap 数组长度    取模运算得到位置, 得到位置，
            将对应位置设为1

    查询key！！！
        
        >>>>>>
            只要有一位是0，就不存在


    ex:  三个函数   hash(key) mod  --     得到三个坑位：   坑位17=1，22=1，35=1
        判断key是否存在 --  对应三个坑位必须都是1，有0则肯定不存在

    高效插入查询，占用空间小， 返回结果  不确定性 + 不完美

    一个元素判定结果：      
        存在    --  元素不一定存在  -- 可能被其他顶用坑位（hash冲突）
        不存在  --  元素一定不存在

    可以添加元素，不能删除元素  --  hash冲突，不确定删除坑位到底是删除的是谁，一个坑位可能存在多个元素

    综上：  
        如果BloomFilter 判断元素不在一个集合中，那一定不存在 
        实际元素数量不能远大于初始数量，一次给够，避免扩容
        实际元素量>初始化量 --  重建布隆过滤器


    >>>应用：
        先布隆过滤器判断是否存在，不存在直接返回，存在则查询cache，数据库，   --  不查询数据库

    Advantage:  
        高效插入 查询
        内存占bit空间少
    Disadvantage：
        不能删除
        存在误判


----------缓存预热--------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    1. 不DB 修改后不主动刷新，等待第一次查询再自动加载
    2. 程序上线后 测试 主动提前触发
    3. 运行脚本，程序 主动加载

----------缓存雪崩--------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    1. 设置key过期时间错开or不过期
    2. 使用集群 高可用
    3. 多缓存结合 --  ehcache + redis
    4. 服务降级 展示错误页面，同时后端修复


----------缓存击穿--------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

    大量请求同时查询同一个Key，key正好失效的，导致大量请求到数据库

    热点Key失效，暴打DB

    1. 设置差异失效时间，热点key 不设置失效时间
        用两套缓存，差异失效，保证始终有一个缓存可以使用
            >>>>>>>>查询：
                查A缓存
                    无  --  查B 缓存
                                无  --  查DB
                                有  --  return
                    有  -- return
            
            >>>>>>>>更新：
                更新B缓存， 先expire，再add，设置过期时间大于A缓存过期时间
                再更新A缓存

            主A，从B， 每次先更新B，设置B 过期时间大于A
                        再更新A缓存

    2. 双检加锁
        >>>>>>>>双检加锁策略    
        1. 查询方法加上一个互斥锁   --  防止大量访问数据库
            a. 第一个线程查cache，有直接返回
            b. cache不存在，加互斥锁，再查一遍cache
            c. cache确实没有，再去数据库
            d. 拿到数据库数据，写到cache，再返回

----------缓存穿透--------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> 

    cache中不存在，DB中也不存在，造成大量访问数据库
    
    --->>> 使用布隆过滤器
        1. 已有数据放过滤器中
        2. 所有请求先走过滤器
            无  --  直接返回无
            有  --  再去redis Cache
                    cache 大概率有  --  返回结果
                    cache 无    --  再去数据库

    空对象缓存      --          治标不治本
        约定默认空值， 比如 字符串： Nah, 并存入redis  --  设置过期时间 短

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

---------------------------    分布式锁        >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    setNx   --  本质上，多个服务设置同一个Key，各个服务能拿到这个key，才允许对redis缓存做修改操作
            --  setnx一般业务没问题，即用即删，但是对于复杂业务，需要可重入锁，则不行

    CAP
        CP:一致性
        AP:高可用性

    1. 宕机，过期 + 防止死锁
        创建锁 setNx   --  命令保证创建key 以及key expire时间的原子性

    2. 防止误删
        删除前对比value是否是当前服务设置的key

    3. Lua保证原子性    --  EVAL "return redis.call('mset',KEYS[1],ARGV[1],KEYS[2],ARGV[2])" 2 kk1 kk2 lua1 lua22 [key ...]] [arg [arg ...]]
        最后会先查询key，对比value保证是当前服务设置的key
        再删除key，释放，让别的服务可以创建key
        ！！！需要保证查询 删除 原子性

    4. 可重入锁(递归锁) + 设计模式      --      获取到锁的当前方法，可能方法内部又会调用其他再次对cache做修改，这时候不需要再次获取锁

        setnx一般业务没问题，即用即删，但是对于复杂业务，需要可重入锁，则不行

        使用：  hset lockKey 业务id 重入次数        加锁次数 == 解锁次数

            ex: EXISTS lockKey                          --  是否有锁

                HSET lockKey UUID.threadId  1           --  加锁，设置初始使用次数：1
                HINCRBY lockKey UUID.threadId  1        --  重入一次
                HINCRBY lockKey UUID.threadId  1        --  再重入一次

                HINCRBY lockKey UUID.threadId  -1       --  解锁一次
                HINCRBY lockKey UUID.threadId  -1       --  再解锁一次
                HINCRBY lockKey UUID.threadId  -1       --  解锁初始化的锁一次

                DEL lockKey                             --  最后删除
                
    5. 分布式锁自动续期
        Lua脚本实现 原子性 --  注意僵尸线程

    6. RedLock
        Redis Master 开启了锁，更新数据，节点挂了，还没来得及复制到salve    --  主从复制异步的
            会造成一锁被多建立多用

        多个奇数个Master node，同时获取锁， 只有大多数node都获取到了（ N/2 +1 ）且锁使用时间<锁失效时间，才算成功获取锁
            N = count(node) = 2X+1

    7. Redisson     --      is a reentrantlock

        RLock lock = redisson.getLock(lockName);

        lock.lock()

        if(lock.isLocked() & lock.isHeldByCurrentThread){
            lock.unLock();
        }

        watchdog       --   分布式锁自动续期    Lua脚本实现  +  递归
            默认30s， 每30s/3=10s 查一次

        MultiLock 多重锁    --      多机案例

        MultiLock lock = redisClient

--------------------------- --------------------------- --------------------------- --------------------------- 
---------------------------    过期淘汰策略        >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
--------------------------- --------------------------- --------------------------- --------------------------- 

redis三种删除策略
    1. 立即删除/定时删除
    2. 惰性删除     --  lazyfree-lazy-eviction=yes
    3. 面两种方案都走极端


2个维度：
    过期键中    筛选
    所有键中    筛选

4个方面：
    LRU 
        最近最少使用页面置换算法，淘汰最长时间未被使用的页面，看页面最后一次被使用到发生调度的时间长短，
            首先淘汰最长时间未被使用的页面。
    LFU 
        最近最不常用页面置换算法，淘汰一定时期内被访问次数最少的页面，看一定时间段内页面被使用的频率，
            淘汰一定时期内被访问次数最少的页
    random 
    ttl

2 X 4 = 8个选项
淘汰策略有哪些(Redis7版本)
    noeviction：不会驱逐任何key，表示即使内存达到上限也不进行置换，所有能引起内存增加的命令都会返回error
    allkeys-lru：对所有key使用LRU算法进行删除，优先删除掉最近最不经常使用的key，用以保存新数据
    volatile-lru：对所有设置了过期时间的key使用LRU算法进行删除
    allkeys-random：对所有key随机删除
    volatile-random：对所有设置了过期时间的key随机删除
    volatile-ttl：删除马山要过期的key
    allkeys-lfu：对所有key使用LFU算法进行删除
    volatile-lfu：对所有设置了过期时间的key使用LFU算法进行删除

如何配置？如何修改？
    直接使用config命令
    直接redis.conf配置文件
redis缓存淘汰策略配置性能建议
    避免存储BigKey
    开启惰性删除，lazyfree-lazy-eviction=yes

--------------------------- --------------------------- --------------------------- --------------------------- 
---------------------------    五大数据类型        >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
--------------------------- --------------------------- --------------------------- --------------------------- 









--------------------------- --------------------------- --------------------------- --------------------------- 
---------------------------    IO多路复用/epoll        >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
--------------------------- --------------------------- --------------------------- --------------------------- 

IO模型
    同步阻塞 IO( BIO    Blocking IO)
    同步非阻塞IO(NIO    New IO)
    异步非阻塞 IO(AIO   Async IO)
    IO 多路复用 
        一个线程处理多个IO流

阻塞 I/O：每个 socket 都要一个线程来等待数据，线程资源浪费严重。
    非阻塞 I/O：虽然不阻塞，但需要不断轮询，效率低。
    多线程/多进程：每个连接一个线程，线程切换开销大，容易崩溃。

    于是就有了 I/O 多路复用模型，它让一个线程就能高效地处理成百上千个连接
        使用传统阻塞 I/O，你需要 1000 个线程。
        使用 epoll，你只需要 1 个线程就能监听所有连接，谁有数据就处理谁。

    Java 的 Selector 就是 I/O 多路复用的抽象，底层在 Linux 上使用 epoll。

select/poll:    windows

epoll: Linux 